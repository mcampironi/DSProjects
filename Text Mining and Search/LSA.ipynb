{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0077b6\"> <center> Text Mining and Search - AA 2020/2021 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0077b6\"> <center> LSA </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <span style=\"color:#00b4d8\">**Studente**:</span> Campironi Matteo\n",
    ">\n",
    "> <span style=\"color:#00b4d8\">**Matricola**:</span> 801850\n",
    "\n",
    "> <span style=\"color:#00b4d8\">**Studente**:</span> Di Maggio Serena\n",
    ">\n",
    "> <span style=\"color:#00b4d8\">**Matricola**:</span> 821063"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importo le librerie necessarie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.cluster.util import cosine_distance\n",
    "from operator import itemgetter\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "import string\n",
    "import pickle\n",
    "import contractions\n",
    "from collections import Counter\n",
    "from sklearn.decomposition import TruncatedSVD \n",
    "from rouge import Rouge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = Rouge()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "WHITE_SPACE_PATTERN = re.compile(r' +')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definisco funzioni utili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            #if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)\n",
    "\n",
    "def stringPreprocessing(text):\n",
    "    text = text.lower() #lowercase\n",
    "    text = contractions.fix(text) #contractions\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) #punctuation\n",
    "    text = re.sub(r'\\d', '', text) #numbers\n",
    "    text = re.sub(WHITE_SPACE_PATTERN, ' ', text.strip()) #whitespaces\n",
    "    text = lemmatize_sentence(text) #lemmatization\n",
    "    tokenizedText = word_tokenize(text) #tokenize\n",
    "    finalText= [item for item in tokenizedText if item not in stop_words] #stopwords\n",
    "    finalText = ' '.join(map(str, finalText))\n",
    "    \n",
    "    return finalText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSA(article):\n",
    "    sentences = sent_tokenize(article)\n",
    "    sentencesPP = [stringPreprocessing(sentence) for sentence in sentences]\n",
    "    \n",
    "    tfidf_matrix = tfidf_vectorizer_fit.transform(sentencesPP) #document-term matrix\n",
    "    \n",
    "    svd = TruncatedSVD(10, algorithm='randomized', n_iter=5, random_state=123)\n",
    "    lsa = svd.fit_transform(tfidf_matrix)\n",
    "    sigma = svd.singular_values_\n",
    "    \n",
    "    column_names = [\"Topic {}\".format(str(i)) for i in range(lsa.shape[1])]\n",
    "    sent_topic_matrix = pd.DataFrame(lsa,columns=column_names)\n",
    "    sent_topic_matrix[\"Document\"] = sentences#PP\n",
    "    sent_topic_matrix[\"Position\"] = [i for i in range(len(sentences))]\n",
    "    dic = tfidf_vectorizer.get_feature_names()\n",
    "    term_topic_matrix = pd.DataFrame(svd.components_, index = column_names, columns = (dic)).T\n",
    "    \n",
    "    return sigma, sent_topic_matrix, term_topic_matrix, lsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(sigma, sent_topic_matrix):\n",
    "    summary = []\n",
    "    column_names = [\"Topic {}\".format(str(i)) for i in range(len(sigma))]\n",
    "    for i in range(len(column_names)):\n",
    "        topic = column_names[i]\n",
    "        sent_topic_matrix.sort_values(by = topic,inplace = True,ascending = False)\n",
    "        sent_topic_matrix.reset_index(drop = True, inplace = True)\n",
    "        item = (sent_topic_matrix[\"Document\"][0],sent_topic_matrix[\"Position\"][0])\n",
    "        if item not in summary:\n",
    "            summary.append(item)\n",
    "                \n",
    "    summary.sort(key = lambda x: x[1]) #ordino per valore di Position\n",
    "    sent = [i[0] for i in summary] #considero solo le frasi \n",
    "    #return \" \".join(sent) \n",
    "    return sent\n",
    "\n",
    "def MMR(sentence, top_summary, article, l=0.5):\n",
    "\n",
    "    sentence = stringPreprocessing(sentence)\n",
    "    \n",
    "    sentence = tfidf_vectorizer_fit.transform([sentence])\n",
    "    article = tfidf_vectorizer_fit.transform([article])\n",
    "    \n",
    "    sim1 = cosine_similarity(sentence, article)\n",
    "    \n",
    "    sim2 = []\n",
    "    for sent in top_summary:\n",
    "        sent = stringPreprocessing(sent)\n",
    "        sent = tfidf_vectorizer_fit.transform([sent])\n",
    "        sim2.append(cosine_similarity(sentence, sent))\n",
    "        \n",
    "    mmr = l*sim1 + (1-l)*max(sim2)\n",
    "    \n",
    "    return mmr[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carico il dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "      <th>articlePP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As ash from Chile's Calbuco Volcano spread eas...</td>\n",
       "      <td>Volcano already has erupted twice this week. I...</td>\n",
       "      <td>ash chile calbuco volcano spread east argentin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baltimore Ravens star running back Ray Rice wa...</td>\n",
       "      <td>Baltimore Raven running back Ray Rice is indic...</td>\n",
       "      <td>baltimore raven star run back ray rice indict ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nine years after \"Bruce Almighty,\" Universal i...</td>\n",
       "      <td>EW has confirmed that Universal has plans to r...</td>\n",
       "      <td>nine year bruce almighty universal plot second...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Former Italian Prime Minister Silvio Berluscon...</td>\n",
       "      <td>A judge in Italy indicts Sergio Berlusconi, ac...</td>\n",
       "      <td>former italian prime minister silvio berluscon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Despite most humans' land-centric view, Earth ...</td>\n",
       "      <td>Oceans make life on Earth possible providing o...</td>\n",
       "      <td>despite human landcentric view earth ocean pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>A teenage girl has died after she jumped out o...</td>\n",
       "      <td>Laikyn Field hit the pavement on Saturday when...</td>\n",
       "      <td>teenage girl die jump parent move car argument...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>Cash on tap: Scarlet Johansson is being paid 2...</td>\n",
       "      <td>Scarlett Johansson admitted to Mail on Sunday ...</td>\n",
       "      <td>cash tap scarlet johansson pay sodastream appe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>With young children inevitably set to ask a ba...</td>\n",
       "      <td>Fun infographic attempts to explain the scienc...</td>\n",
       "      <td>young child inevitably set ask barrage questio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>Prince Harry proved he is an excellent uncle-t...</td>\n",
       "      <td>Prince was pictured holding the bear as he lan...</td>\n",
       "      <td>prince harry prove excellent uncletobe handdel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>It's not every day two senior barristers in th...</td>\n",
       "      <td>The City of Knox council made an 'administrati...</td>\n",
       "      <td>every day two senior barrister nation high cou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 article  \\\n",
       "0      As ash from Chile's Calbuco Volcano spread eas...   \n",
       "1      Baltimore Ravens star running back Ray Rice wa...   \n",
       "2      Nine years after \"Bruce Almighty,\" Universal i...   \n",
       "3      Former Italian Prime Minister Silvio Berluscon...   \n",
       "4      Despite most humans' land-centric view, Earth ...   \n",
       "...                                                  ...   \n",
       "19995  A teenage girl has died after she jumped out o...   \n",
       "19996  Cash on tap: Scarlet Johansson is being paid 2...   \n",
       "19997  With young children inevitably set to ask a ba...   \n",
       "19998  Prince Harry proved he is an excellent uncle-t...   \n",
       "19999  It's not every day two senior barristers in th...   \n",
       "\n",
       "                                                 summary  \\\n",
       "0      Volcano already has erupted twice this week. I...   \n",
       "1      Baltimore Raven running back Ray Rice is indic...   \n",
       "2      EW has confirmed that Universal has plans to r...   \n",
       "3      A judge in Italy indicts Sergio Berlusconi, ac...   \n",
       "4      Oceans make life on Earth possible providing o...   \n",
       "...                                                  ...   \n",
       "19995  Laikyn Field hit the pavement on Saturday when...   \n",
       "19996  Scarlett Johansson admitted to Mail on Sunday ...   \n",
       "19997  Fun infographic attempts to explain the scienc...   \n",
       "19998  Prince was pictured holding the bear as he lan...   \n",
       "19999  The City of Knox council made an 'administrati...   \n",
       "\n",
       "                                               articlePP  \n",
       "0      ash chile calbuco volcano spread east argentin...  \n",
       "1      baltimore raven star run back ray rice indict ...  \n",
       "2      nine year bruce almighty universal plot second...  \n",
       "3      former italian prime minister silvio berluscon...  \n",
       "4      despite human landcentric view earth ocean pla...  \n",
       "...                                                  ...  \n",
       "19995  teenage girl die jump parent move car argument...  \n",
       "19996  cash tap scarlet johansson pay sodastream appe...  \n",
       "19997  young child inevitably set ask barrage questio...  \n",
       "19998  prince harry prove excellent uncletobe handdel...  \n",
       "19999  every day two senior barrister nation high cou...  \n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"df.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer_fit = tfidf_vectorizer.fit(df['articlePP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcampironi/.local/lib/python3.8/site-packages/sklearn/decomposition/_truncated_svd.py:197: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "/home/mcampironi/.local/lib/python3.8/site-packages/sklearn/decomposition/_truncated_svd.py:197: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "/home/mcampironi/.local/lib/python3.8/site-packages/sklearn/decomposition/_truncated_svd.py:197: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "/home/mcampironi/.local/lib/python3.8/site-packages/sklearn/decomposition/_truncated_svd.py:197: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "/home/mcampironi/.local/lib/python3.8/site-packages/sklearn/decomposition/_truncated_svd.py:197: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8h 34min 39s, sys: 4h 59min 47s, total: 13h 34min 27s\n",
      "Wall time: 5h 53min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "summaries = []\n",
    "\n",
    "for i in range(20000):\n",
    "    sigma, sent_topic_matrix, term_topic_matrix, lsa = LSA(df['article'][i])\n",
    "    summary = summarize(sigma,sent_topic_matrix)\n",
    "    mmr = []\n",
    "    for sent in summary[:min(10, len(summary))]:\n",
    "        mmr.append(MMR(sent, summary[:10], df[\"articlePP\"][i], 0.5))\n",
    "    mmr = np.array(mmr)\n",
    "    mmr_ind = mmr.argsort()[-4:][::-1]\n",
    "    mmr_sentence = [summary[i] for i in mmr_ind]\n",
    "    summaries.append(' '.join(mmr_sentence))\n",
    "    \n",
    "df[\"summary_tr\"] = summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "      <th>articlePP</th>\n",
       "      <th>summary_tr</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As ash from Chile's Calbuco Volcano spread eas...</td>\n",
       "      <td>Volcano already has erupted twice this week. I...</td>\n",
       "      <td>ash chile calbuco volcano spread east argentin...</td>\n",
       "      <td>As ash from Chile's Calbuco Volcano spread eas...</td>\n",
       "      <td>0.178218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baltimore Ravens star running back Ray Rice wa...</td>\n",
       "      <td>Baltimore Raven running back Ray Rice is indic...</td>\n",
       "      <td>baltimore raven star run back ray rice indict ...</td>\n",
       "      <td>Rice's attorney, Michael Diamondstein, could n...</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nine years after \"Bruce Almighty,\" Universal i...</td>\n",
       "      <td>EW has confirmed that Universal has plans to r...</td>\n",
       "      <td>nine year bruce almighty universal plot second...</td>\n",
       "      <td>This wouldn't be the first \"Bruce\" sequel; \"Ev...</td>\n",
       "      <td>0.466258</td>\n",
       "      <td>0.360248</td>\n",
       "      <td>0.478261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Former Italian Prime Minister Silvio Berluscon...</td>\n",
       "      <td>A judge in Italy indicts Sergio Berlusconi, ac...</td>\n",
       "      <td>former italian prime minister silvio berluscon...</td>\n",
       "      <td>Silvio Berlusconi, so long!. Because of his ag...</td>\n",
       "      <td>0.109890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Despite most humans' land-centric view, Earth ...</td>\n",
       "      <td>Oceans make life on Earth possible providing o...</td>\n",
       "      <td>despite human landcentric view earth ocean pla...</td>\n",
       "      <td>And it's not just the trenches that need to be...</td>\n",
       "      <td>0.125654</td>\n",
       "      <td>0.042328</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>A teenage girl has died after she jumped out o...</td>\n",
       "      <td>Laikyn Field hit the pavement on Saturday when...</td>\n",
       "      <td>teenage girl die jump parent move car argument...</td>\n",
       "      <td>Tragedy: Laikyn Field, 16, hit the pavement af...</td>\n",
       "      <td>0.369863</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.336134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>Cash on tap: Scarlet Johansson is being paid 2...</td>\n",
       "      <td>Scarlett Johansson admitted to Mail on Sunday ...</td>\n",
       "      <td>cash tap scarlet johansson pay sodastream appe...</td>\n",
       "      <td>The charity insists it is incompatible for Joh...</td>\n",
       "      <td>0.174603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>With young children inevitably set to ask a ba...</td>\n",
       "      <td>Fun infographic attempts to explain the scienc...</td>\n",
       "      <td>young child inevitably set ask barrage questio...</td>\n",
       "      <td>The total number of presents would set Santa b...</td>\n",
       "      <td>0.358025</td>\n",
       "      <td>0.212500</td>\n",
       "      <td>0.355556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>Prince Harry proved he is an excellent uncle-t...</td>\n",
       "      <td>Prince was pictured holding the bear as he lan...</td>\n",
       "      <td>prince harry prove excellent uncletobe handdel...</td>\n",
       "      <td>A friend told the paper that Harry wants to ge...</td>\n",
       "      <td>0.313043</td>\n",
       "      <td>0.053097</td>\n",
       "      <td>0.298851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>It's not every day two senior barristers in th...</td>\n",
       "      <td>The City of Knox council made an 'administrati...</td>\n",
       "      <td>every day two senior barrister nation high cou...</td>\n",
       "      <td>In September 2013, Izzy's owner Ms Isbester pl...</td>\n",
       "      <td>0.317460</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.279330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19999 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 article  \\\n",
       "0      As ash from Chile's Calbuco Volcano spread eas...   \n",
       "1      Baltimore Ravens star running back Ray Rice wa...   \n",
       "2      Nine years after \"Bruce Almighty,\" Universal i...   \n",
       "3      Former Italian Prime Minister Silvio Berluscon...   \n",
       "4      Despite most humans' land-centric view, Earth ...   \n",
       "...                                                  ...   \n",
       "19994  A teenage girl has died after she jumped out o...   \n",
       "19995  Cash on tap: Scarlet Johansson is being paid 2...   \n",
       "19996  With young children inevitably set to ask a ba...   \n",
       "19997  Prince Harry proved he is an excellent uncle-t...   \n",
       "19998  It's not every day two senior barristers in th...   \n",
       "\n",
       "                                                 summary  \\\n",
       "0      Volcano already has erupted twice this week. I...   \n",
       "1      Baltimore Raven running back Ray Rice is indic...   \n",
       "2      EW has confirmed that Universal has plans to r...   \n",
       "3      A judge in Italy indicts Sergio Berlusconi, ac...   \n",
       "4      Oceans make life on Earth possible providing o...   \n",
       "...                                                  ...   \n",
       "19994  Laikyn Field hit the pavement on Saturday when...   \n",
       "19995  Scarlett Johansson admitted to Mail on Sunday ...   \n",
       "19996  Fun infographic attempts to explain the scienc...   \n",
       "19997  Prince was pictured holding the bear as he lan...   \n",
       "19998  The City of Knox council made an 'administrati...   \n",
       "\n",
       "                                               articlePP  \\\n",
       "0      ash chile calbuco volcano spread east argentin...   \n",
       "1      baltimore raven star run back ray rice indict ...   \n",
       "2      nine year bruce almighty universal plot second...   \n",
       "3      former italian prime minister silvio berluscon...   \n",
       "4      despite human landcentric view earth ocean pla...   \n",
       "...                                                  ...   \n",
       "19994  teenage girl die jump parent move car argument...   \n",
       "19995  cash tap scarlet johansson pay sodastream appe...   \n",
       "19996  young child inevitably set ask barrage questio...   \n",
       "19997  prince harry prove excellent uncletobe handdel...   \n",
       "19998  every day two senior barrister nation high cou...   \n",
       "\n",
       "                                              summary_tr    rouge1    rouge2  \\\n",
       "0      As ash from Chile's Calbuco Volcano spread eas...  0.178218  0.000000   \n",
       "1      Rice's attorney, Michael Diamondstein, could n...  0.211538  0.019608   \n",
       "2      This wouldn't be the first \"Bruce\" sequel; \"Ev...  0.466258  0.360248   \n",
       "3      Silvio Berlusconi, so long!. Because of his ag...  0.109890  0.000000   \n",
       "4      And it's not just the trenches that need to be...  0.125654  0.042328   \n",
       "...                                                  ...       ...       ...   \n",
       "19994  Tragedy: Laikyn Field, 16, hit the pavement af...  0.369863  0.097222   \n",
       "19995  The charity insists it is incompatible for Joh...  0.174603  0.000000   \n",
       "19996  The total number of presents would set Santa b...  0.358025  0.212500   \n",
       "19997  A friend told the paper that Harry wants to ge...  0.313043  0.053097   \n",
       "19998  In September 2013, Izzy's owner Ms Isbester pl...  0.317460  0.080000   \n",
       "\n",
       "         rougel  \n",
       "0      0.175824  \n",
       "1      0.208333  \n",
       "2      0.478261  \n",
       "3      0.075000  \n",
       "4      0.111111  \n",
       "...         ...  \n",
       "19994  0.336134  \n",
       "19995  0.166667  \n",
       "19996  0.355556  \n",
       "19997  0.298851  \n",
       "19998  0.279330  \n",
       "\n",
       "[19999 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge1 = []\n",
    "rouge2 = []\n",
    "rougel = []\n",
    "\n",
    "for i in range(19999):\n",
    "    scores = rouge.get_scores(df[\"summary\"][i], df[\"summary_tr\"][i])\n",
    "    rouge1.append(scores[0][\"rouge-1\"][\"f\"])\n",
    "    rouge2.append(scores[0][\"rouge-2\"][\"f\"])\n",
    "    rougel.append(scores[0][\"rouge-l\"][\"f\"])\n",
    "    \n",
    "df[\"rouge1\"] = rouge1\n",
    "df[\"rouge2\"] = rouge2\n",
    "df[\"rougel\"] = rougel\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"df_LSA.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcolo Rouge medio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'f': 0.2523573592410816,\n",
       "  'p': 0.3836043218419657,\n",
       "  'r': 0.2001420237561898},\n",
       " 'rouge-2': {'f': 0.08181539976081688,\n",
       "  'p': 0.12685501675886104,\n",
       "  'r': 0.06426629355976811},\n",
       " 'rouge-l': {'f': 0.24591101391376807,\n",
       "  'p': 0.34629038904391,\n",
       "  'r': 0.20085598389669282}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge.get_scores(df[\"summary\"], df[\"summary_tr\"], avg=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
